---
# Disable by default so that existing deployments don't break when bucket isn't configured
# Can be overwritten in azimuth-config as needed
velero_enabled: false

# Whether or not to set the ansible no_log parameter on tasks in the role involving credentials.
# This should only ever be set false for temporary debugging purposes.
velero_no_log: true

#####
# Velero installation and setup config
#####

# Velero CLI installation config
velero_cli_version: v1.13.0
velero_cli_arch: linux-amd64
velero_cli_download_url: "https://github.com/vmware-tanzu/velero/releases/download/{{ velero_cli_version }}/velero-{{ velero_cli_version }}-{{ velero_cli_arch }}.tar.gz"

# The URL endpoint for the target object store
velero_s3_url: "{{ undef(hint='velero_s3_url must be set to the url of your target object store') }}"

# The name of a pre-existing bucket in the target object store
velero_bucket_name: "{{ undef(hint='velero_bucket_name must be set to an existing bucket in the target object store') }}"

# The name to use for the created cluster secret containing the object store credentials
velero_s3_creds_secret_name: velero-s3-config

# S3 credentials (should be set in a git-crypt encrypted secrets file!)
velero_aws_access_key_id: "{{ undef(hint='velero_aws_access_key_id and velero_aws_secret_access_key must be set to provide credentials for the target object store') }}"
velero_aws_secret_access_key: "{{ undef(hint='velero_aws_access_key_id and velero_aws_secret_access_key must be set to provide credentials for the target object store') }}"

# Kubernetes CSI Snapshot Controller config
velero_csi_snapshot_controller_chart_name: snapshot-controller
velero_csi_snapshot_controller_chart_repo: https://piraeus.io/helm-charts/
velero_csi_snapshot_controller_chart_version: 2.2.0
velero_csi_snapshot_controller_release_namespace: kube-system
velero_csi_snapshot_controller_release_name: csi-snapshot-controller
velero_csi_snapshot_controller_wait_timeout: 10m
velero_csi_snapshot_controller_release_defaults: {}
velero_csi_snapshot_controller_release_overrides: {}
velero_csi_snapshot_controller_release_values: >-
  {{-
    velero_csi_snapshot_controller_release_defaults |
      combine(velero_csi_snapshot_controller_release_overrides, recursive = True)
  }}

# The name to give to the installed volume snapshot class
velero_k8s_cinder_snapshot_class_name: cinder-csi-snapshot

# Velero plugin config
velero_s3_plugin_image_source: velero/velero-plugin-for-aws
velero_s3_plugin_image_version: v1.9.0
velero_csi_plugin_image_source: velero/velero-plugin-for-csi
velero_csi_plugin_image_version: v0.7.0

# Velero Helm chart config
velero_chart_name: velero
velero_chart_repo: https://vmware-tanzu.github.io/helm-charts
velero_chart_version: 5.3.0
velero_release_namespace: velero
velero_release_name: velero
velero_wait_timeout: 10m
velero_release_defaults:
  configuration:
    backupsEnabled: true
    backupStorageLocation:
      - name: s3
        default: true
        provider: aws
        bucket: "{{ velero_bucket_name }}"
        credential:
          name: "{{ velero_s3_creds_secret_name }}"
          key: s3-creds
        config:
          region: required-but-not-used
          s3ForcePathStyle: true
          s3Url: "{{ velero_s3_url }}"

    # Use CSI snapshotter instead
    volumeSnapshotLocation: []

  initContainers:
    - name: velero-plugin-for-aws
      image: "{{ velero_s3_plugin_image_source }}:{{ velero_s3_plugin_image_version }}"
      imagePullPolicy: IfNotPresent
      volumeMounts:
        - mountPath: /target
          name: plugins
    - name: velero-plugin-for-csi
      image: "{{ velero_csi_plugin_image_source }}:{{ velero_csi_plugin_image_version }}"
      imagePullPolicy: IfNotPresent
      volumeMounts:
        - mountPath: /target
          name: plugins

velero_release_overrides: {}
velero_release_values: >-
  {{-
    velero_release_defaults |
      combine(velero_release_overrides, recursive = True)
  }}



#####
# Velero backup config
#####

# List of additional namespaces to exclude from backup
velero_backup_exclude_namespaces_default: []
velero_backup_exclude_namespaces_extra: []
velero_backup_exclude_namespaces: "{{ [velero_backup_exclude_namespaces_default, velero_backup_exclude_namespaces_extra] | flatten }}"



#####
# Velero backup schedule config
#####

# Whether or not to enable the regular backup schedule
# Note: Setting this to false will still install the 
# BackupSchedule resource onto the cluster to allow adhoc
# backups using `velero backup create --from-schedule <name>`
# This option simply controls the schedule's spec.paused field.
velero_backup_schedule_enabled: true

# Name for backup schedule kubernetes resource
velero_backup_schedule_name: default

# Schedule to use for backups (defaults to every day at midnight)
# See https://en.wikipedia.org/wiki/Cron for format options
velero_backup_schedule_timings: "0 0 * * *"

# Time-to-live for existing backups (defaults to 7 days)
# See https://pkg.go.dev/time#ParseDuration for duration format options
velero_backup_schedule_ttl: "168h"

# TODO: Configure alerts for failed backups
# See https://github.com/vmware-tanzu/helm-charts/blob/1e6a5b46a59d2dae8153fa8c0794bad84e1d63e1/charts/velero/values.yaml#L239



#####
# Velero restore config (applies to stackhpc.azimuth_ops.restore playbook)
#####

# Name of restore object to create
velero_restore_name: "velero-backup-restore--{{ '%Y-%m-%d--%H-%M-%S' | strftime(ansible_date_time.epoch) }}"

# Name of backup to use for restore process
velero_restore_backup_name: "{{ undef(hint='velero_restore_backup_name must be set to the name of an existing backup in your configured object store') }}"

# List of resources for which the status field of the k8s object 
# should be restored. These are directly passed to the 
# `--status-include-resources` arg of `velero restore create` command
velero_restore_include_resource_status_defaults:
  # Identity operator resources
  - realms.identity.azimuth.stackhpc.com
  # CaaS platform resources
  - clusters.caas.azimuth.stackhpc.com
  # CAPI platform resources
  - clusters.azimuth.stackhpc.com
  - kubeadmconfigs.bootstrap.cluster.x-k8s.io
  - kubeadmcontrolplanes.controlplane.cluster.x-k8s.io
  - machinedeployments.cluster.x-k8s.io
  - machinehealthchecks.cluster.x-k8s.io
  - machinepools.cluster.x-k8s.io
  - machines.cluster.x-k8s.io
  - machinesets.cluster.x-k8s.io
  - openstackclusters.infrastructure.cluster.x-k8s.io
  - openstackmachines.infrastructure.cluster.x-k8s.io
velero_restore_include_resource_status_extra: []
velero_restore_include_resource_status: "{{ [velero_restore_include_resource_status_defaults, velero_restore_include_resource_status_extra] | flatten }}"

# List of namespaces to exclude from backup
# NOTE: This list should only contain items that are not listed
# in velero_backup_exclude_namespaces since namespaces excluded
# from the backup will, by definition, also be excluded from the 
# restore. This list is primarily useful for development purposes
# to test whether a namespace is actually required for a restore
# to complete successfully.
velero_restore_exclude_namespaces_default: []
velero_restore_exclude_namespaces_extra: []
velero_restore_exclude_namespaces: "{{ [velero_restore_exclude_namespaces_default, velero_restore_exclude_namespaces_extra] | flatten }}"

# List of resource types to exclude from restore process
velero_restore_exclude_resources_defaults:
  # Profiles cannot be explicitly created via k8s api
  # and get recreated automatically by calico anyway
  - profiles.projectcalico.org
velero_restore_exclude_resources_extra: []
velero_restore_exclude_resources: "{{ [velero_restore_exclude_resources_defaults, velero_restore_exclude_resources_extra] | flatten }}"

# Maximum number of restore passes to attempt
velero_max_restore_passes: 3

# Timeout in seconds for each restore pass
velero_restore_attempt_timeout: 1800

# Only allow restores from backups with status 'Completed'
# and bail if status is 'PartiallyFailed' (or anything else)
velero_restore_strict: true
