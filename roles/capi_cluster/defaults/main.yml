---

# The chart to use
capi_cluster_chart_repo: https://stackhpc.github.io/capi-helm-charts
capi_cluster_chart_name: openstack-cluster
capi_cluster_chart_version: 0.1.4

# Release information for the cluster release
capi_cluster_release_namespace: default
capi_cluster_release_name: "{{ undef(hint = 'capi_cluster_release_name is required')}}"

# The state of the cluster - present to install/update, absent to delete
capi_cluster_release_state: present

# Read the credentials for the deployment from the current clouds.yaml by default
capi_cluster_clouds_file: >-
  {{-
    lookup('env', 'OS_CLIENT_CONFIG_FILE') or
    undef(hint = 'capi_cluster_clouds_file is required')
  }}
capi_cluster_credentials: "{{ lookup('file', capi_cluster_clouds_file) | from_yaml }}"
# The cloud to use in the clouds file
capi_cluster_cloud_name: "{{ lookup('env', 'OS_CLOUD') or 'openstack' }}"
# The OpenStack Cluster API provider requires the project ID to be present in the clouds file
capi_cluster_openstack_project_id: "{{ undef(hint = 'capi_cluster_openstack_project_id is required') }}"

# The CA certificate to use to validate OpenStack connections
# If not given, then connections are not verified
capi_cluster_openstack_ca_cert_file:
capi_cluster_openstack_ca_cert: >-
  {{-
    lookup('file', capi_cluster_openstack_ca_cert_file)
    if capi_cluster_openstack_ca_cert_file
    else None
  }}

# The Kubernetes version of the cluster and the id of the matching image
# Default, wire these up with an image from community images when available
capi_cluster_kubernetes_version: >-
  {{-
    community_images.kube_1_26.kubernetes_version
    if community_images is defined and 'kube_1_26' in community_images
    else undef(hint = 'capi_cluster_kubernetes_version is required')
  }}
capi_cluster_machine_image_id: >-
  {{-
    community_images_image_ids.kube_1_26
    if (
      community_images_image_ids is defined and
      'kube_1_26' in community_images_image_ids
    )
    else undef(hint = 'capi_cluster_machine_image_id is required')
  }}

# The SSH key to use
# Defaults to the deploy key created by Terraform if available
capi_cluster_ssh_keypair: >-
  {{-
    infra_deploy_keypair
    if infra_deploy_keypair is defined
    else undef(hint = 'capi_cluster_ssh_keypair is required')
  }}

# Bundle of certificates that should be added to the system trustroots of cluster nodes
# E.g. if using a registry with a custom CA chain
capi_cluster_trust_bundle: "{{ trust_bundle | default({}) }}"

# The registry mirrors for the cluster
# NOTE: This cannot depend on Harbor as it isn't deployed yet!
#       However if you maintain, for example, a Docker Hub mirror for your site
#       independently of Azimuth, you can use that
capi_cluster_registry_mirrors: {}

# Any registry authentication to add to cluster nodes
# This allows containerd to authenticate directly without requiring imagePullSecrets
capi_cluster_registry_auth: {}
  # registry-1.docker.io:
  #   username: "<username>"
  #   password: "<password>"

# The internal network to use
# Defaults to the network created by Terraform if available
# Otherwise, if left empty a network will be created
capi_cluster_internal_network_id: >-
  {{-
    infra_network_id
    if infra_network_id is defined
    else None
  }}
# The external network to use
# If not given, the external network will be detected
# Required if multiple external networks are present
capi_cluster_external_network_id: >-
  {{
    infra_external_network_id
    if infra_external_network_id is defined
    else None
  }}

# Indicates the CIDR blocks to use for pods and services respectively
# Leave blank for the chart defaults
capi_cluster_pods_cidr:
capi_cluster_services_cidr:

# The DNS nameservers for the cluster
# Leave blank for the chart defaults
capi_cluster_dns_nameservers:

# Indicates whether the API server should have a load balancer and a floating IP
# By default, we use a load balancer without a floating IP so that the API is only reachable from the seed node
capi_cluster_apiserver_load_balancer: true
capi_cluster_apiserver_floating_ip: false
# The provider to use for the API server load balancer
capi_cluster_apiserver_loadbalancer_provider:

# The name of the flavors to use for control plane and worker nodes respectively
capi_cluster_control_plane_flavor: >-
  {{ undef(hint = 'capi_cluster_control_plane_flavor is required') }}
capi_cluster_worker_flavor: >-
  {{ undef(hint = 'capi_cluster_worker_flavor is required') }}

# The number of control plane nodes to use
capi_cluster_control_plane_count: 3
# The number of workers to use
capi_cluster_worker_count: 3
# max_unavailable and max_surge are set so that a new worker is made available to the cluster before one is deleted
# The maximum number of machines that can be unavailable during an upgrade
capi_cluster_worker_max_unavailable: 0
# The maximum number of machines that can be scheduled above the desired count during an upgrade
capi_cluster_worker_max_surge: 1

# Indicates whether the failure domain (availability zone) should be omitted from control plane nodes
# Omitting the failure domain allows OpenStack to select a suitable AZ based on other scheduling constraints
capi_cluster_control_plane_omit_failure_domain: false
# A list of failure domains (availability zones) to consider for control plane nodes
# Only used when capi_cluster_control_plane_omit_failure_domain = false
# If not given, all availability zones will be considered for control plane nodes
capi_cluster_control_plane_failure_domains:
# The failure domain (availability zone) to use for workers
# Set to null to let OpenStack select a suitable AZ based on other scheduling constraints
capi_cluster_worker_failure_domain: nova

# The size of the root disks if boot-from-volume is required
# Leave blank to use the root disk from the flavor
capi_cluster_root_volume_size:
capi_cluster_control_plane_root_volume_size: "{{ capi_cluster_root_volume_size }}"
capi_cluster_worker_root_volume_size: "{{ capi_cluster_root_volume_size }}"
# The volume type for the root disk
# Leave blank for the default volume type
capi_cluster_root_volume_type:
capi_cluster_control_plane_root_volume_type: "{{ capi_cluster_root_volume_type }}"
capi_cluster_worker_root_volume_type: "{{ capi_cluster_root_volume_type }}"
# The Cinder availability zone for the root disk
# If set to null, the compute availability zone for the node will be used
capi_cluster_root_volume_availability_zone:
capi_cluster_control_plane_root_volume_availability_zone: "{{ capi_cluster_root_volume_availability_zone }}"
capi_cluster_worker_root_volume_availability_zone: "{{ capi_cluster_root_volume_availability_zone }}"

# Configuration for addons
#   Determines if the ingress controller should be enabled
capi_cluster_addons_ingress_enabled: "{{ ingress_controller_enabled | default(true) }}"
#   Require the specification of a pre-allocated IP for the ingress load balancer
#   This IP should have the wildcard domain assigned to it
capi_cluster_addons_ingress_load_balancer_ip: >-
  {{-
    undef(hint = 'capi_cluster_addons_ingress_load_balancer_ip is required')
    if capi_cluster_addons_ingress_enabled
    else None
  }}
#   Options for LoadBalancer services

#   https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/openstack-cloud-controller-manager/using-openstack-cloud-controller-manager.md#load-balancer
capi_cluster_addons_openstack_loadbalancer_method: >-
  {{-
    'SOURCE_IP_PORT'
    if capi_cluster_addons_openstack_loadbalancer_provider == 'ovn'
    else None
    }}

capi_cluster_addons_openstack_loadbalancer_provider:
capi_cluster_addons_openstack_loadbalancer_create_monitor:
capi_cluster_addons_openstack_loadbalancer_monitor_delay:
capi_cluster_addons_openstack_loadbalancer_monitor_max_retries:
capi_cluster_addons_openstack_loadbalancer_monitor_timeout:
capi_cluster_addons_openstack_loadbalancer_flavor_id:
capi_cluster_addons_openstack_loadbalancer_availability_zone:
capi_cluster_addons_openstack_loadbalancer_max_shared_lb:
#   The metadata search order
capi_cluster_addons_openstack_metadata_search_order:
#   Options for OpenStack block storage
#   https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/cinder-csi-plugin/using-cinder-csi-plugin.md#block-storage
capi_cluster_addons_openstack_block_storage_node_volume_attach_limit:
capi_cluster_addons_openstack_block_storage_rescan_on_resize:
capi_cluster_addons_openstack_block_storage_ignore_volume_az: true
#   The availability zone for the default Cinder CSI storage class
capi_cluster_addons_csi_cinder_availability_zone: nova
#   The Cinder volume type for the default Cinder CSI storage class
capi_cluster_addons_csi_cinder_volume_type:
#   Retention settings for Alertmanager
capi_cluster_addons_monitoring_alertmanager_retention: 168h
capi_cluster_addons_monitoring_alertmanager_volume_size: 10Gi
#   Retention settings for Prometheus metrics
#   The metrics will be retained either for the retention time or until the volume is full
capi_cluster_addons_monitoring_prometheus_retention: 90d
capi_cluster_addons_monitoring_prometheus_volume_size: 10Gi
#   Retention settings for logs in Loki
capi_cluster_addons_monitoring_loki_retention: 744h
capi_cluster_addons_monitoring_loki_volume_size: 10Gi

# The values for the release
capi_cluster_release_defaults:
  kubernetesVersion: "{{ capi_cluster_kubernetes_version }}"
  machineImageId: "{{ capi_cluster_machine_image_id }}"
  machineSSHKeyName: "{{ capi_cluster_ssh_keypair }}"
  clusterNetworking: >-
    {{-
      {} |
        combine(
          { "dnsNameservers": capi_cluster_dns_nameservers }
          if capi_cluster_dns_nameservers
          else {},
          recursive = True
        ) |
        combine(
          {
            "internalNetwork": {
              "networkFilter": {
                "id": capi_cluster_internal_network_id
              }
            }
          }
          if capi_cluster_internal_network_id
          else {},
          recursive = True
        ) |
        combine(
          { "externalNetworkId": capi_cluster_external_network_id }
          if capi_cluster_external_network_id
          else {},
          recursive = True
        )
    }}
  kubeNetwork:
    pods: >-
      {{-
        { "cidrBlocks": [capi_cluster_pods_cidr] }
        if capi_cluster_pods_cidr
        else {}
      }}
    services: >-
      {{-
        { "cidrBlocks": [capi_cluster_services_cidr] }
        if capi_cluster_services_cidr
        else {}
      }}
  trustedCAs: "{{ capi_cluster_trust_bundle }}"
  registryAuth: "{{ capi_cluster_registry_auth }}"
  registryMirrors: "{{ capi_cluster_registry_mirrors }}"
  apiServer: >-
    {{-
      {
        "enableLoadBalancer": capi_cluster_apiserver_load_balancer,
        "associateFloatingIP": capi_cluster_apiserver_floating_ip
      } |
        combine(
          { "loadBalancerProvider": capi_cluster_apiserver_loadbalancer_provider }
          if capi_cluster_apiserver_loadbalancer_provider
          else {}
        )
    }}
  controlPlane:
    machineCount: "{{ capi_cluster_control_plane_count }}"
    machineFlavor: "{{ capi_cluster_control_plane_flavor }}"
    omitFailureDomain: "{{ capi_cluster_control_plane_omit_failure_domain }}"
    failureDomains: "{{ capi_cluster_control_plane_failure_domains }}"
    machineRootVolume: >-
      {{-
        {} |
          combine(
            { "diskSize": capi_cluster_control_plane_root_volume_size }
            if capi_cluster_control_plane_root_volume_size
            else {}
          ) |
          combine(
            { "volumeType": capi_cluster_control_plane_root_volume_type }
            if capi_cluster_control_plane_root_volume_type
            else {}
          ) |
          combine(
            { "availabilityZone": capi_cluster_control_plane_root_volume_availability_zone }
            if capi_cluster_control_plane_root_volume_availability_zone
            else {}
          )
      }}
  nodeGroupDefaults:
    failureDomain: "{{ capi_cluster_worker_failure_domain }}"
    machineFlavor: "{{ capi_cluster_worker_flavor }}"
    machineRootVolume: >-
      {{-
        {} |
          combine(
            { "diskSize": capi_cluster_worker_root_volume_size }
            if capi_cluster_worker_root_volume_size
            else {}
          ) |
          combine(
            { "volumeType": capi_cluster_worker_root_volume_type }
            if capi_cluster_worker_root_volume_type
            else {}
          ) |
          combine(
            { "availabilityZone": capi_cluster_worker_root_volume_availability_zone }
            if capi_cluster_worker_root_volume_availability_zone
            else {}
          )
      }}
    rolloutStrategy:
      type: RollingUpdate
      rollingUpdate:
        maxUnavailable: "{{ capi_cluster_worker_max_unavailable }}"
        maxSurge: "{{ capi_cluster_worker_max_surge }}"
  nodeGroups:
    - name: md-0
      machineCount: "{{ capi_cluster_worker_count }}"
  addons:
    # NFD and the NVIDIA operator are only needed for consuming GPUs
    nodeFeatureDiscovery:
      enabled: false
    nvidiaGPUOperator:
      enabled: false
    # The Mellanox operator is only required for high-performance networking
    mellanoxNetworkOperator:
      enabled: false
    # The NGINX ingress controller is required
    ingress:
      enabled: "{{ capi_cluster_addons_ingress_enabled }}"
      nginx:
        release:
          values:
            controller:
              # We need to be able to use snippet annotations
              allowSnippetAnnotations: true
              service: >-
                {{-
                  {
                    "loadBalancerIP": capi_cluster_addons_ingress_load_balancer_ip,
                  }
                  if capi_cluster_addons_ingress_enabled
                  else {}
                }}
    # Configure monitoring and alerting
    monitoring:
      enabled: true
      kubePrometheusStack:
        release:
          values:
            alertmanager:
              alertmanagerSpec:
                retention: "{{ capi_cluster_addons_monitoring_alertmanager_retention }}"
                storage:
                  volumeClaimTemplate:
                    spec:
                      resources:
                        requests:
                          storage: "{{ capi_cluster_addons_monitoring_alertmanager_volume_size }}"
            prometheus:
              prometheusSpec:
                retention: "{{ capi_cluster_addons_monitoring_prometheus_retention }}"
                storageSpec:
                  volumeClaimTemplate:
                    spec:
                      resources:
                        requests:
                          storage: "{{ capi_cluster_addons_monitoring_prometheus_volume_size }}"
      lokiStack:
        release:
          values:
            loki:
              config:
                limits_config:
                  retention_period: "{{ capi_cluster_addons_monitoring_loki_retention }}"
              persistence:
                size: "{{ capi_cluster_addons_monitoring_loki_volume_size }}"
    # Configure the OpenStack integrations
    openstack:
      cloudConfig:
        LoadBalancer: >-
          {{-
            {} |
              combine(
                { "lb-method": capi_cluster_addons_openstack_loadbalancer_method }
                if capi_cluster_addons_openstack_loadbalancer_method
                else {}
              ) |
              combine(
                { "lb-provider": capi_cluster_addons_openstack_loadbalancer_provider }
                if capi_cluster_addons_openstack_loadbalancer_provider
                else {}
              ) |
              combine(
                { "create-monitor": "true" }
                if capi_cluster_addons_openstack_loadbalancer_create_monitor
                else {}
              ) |
              combine(
                { "monitor-delay": capi_cluster_addons_openstack_loadbalancer_monitor_delay }
                if capi_cluster_addons_openstack_loadbalancer_monitor_delay
                else {}
              ) |
              combine(
                { "monitor-max-retries": capi_cluster_addons_openstack_loadbalancer_monitor_max_retries }
                if capi_cluster_addons_openstack_loadbalancer_monitor_max_retries
                else {}
              ) |
              combine(
                { "monitor-timeout": capi_cluster_addons_openstack_loadbalancer_monitor_timeout }
                if capi_cluster_addons_openstack_loadbalancer_monitor_timeout
                else {}
              ) |
              combine(
                { "flavor-id": capi_cluster_addons_openstack_loadbalancer_flavor_id }
                if capi_cluster_addons_openstack_loadbalancer_flavor_id
                else {}
              ) |
              combine(
                { "availability-zone": capi_cluster_addons_openstack_loadbalancer_availability_zone }
                if capi_cluster_addons_openstack_loadbalancer_availability_zone
                else {}
              ) |
              combine(
                { "max-shared-lb": capi_cluster_addons_openstack_loadbalancer_max_shared_lb }
                if capi_cluster_addons_openstack_loadbalancer_max_shared_lb
                else {}
              )
          }}
        Metadata: >-
          {{-
            {} |
              combine(
                { "search-order": capi_cluster_addons_openstack_metadata_search_order }
                if capi_cluster_addons_openstack_metadata_search_order
                else {}
              )
          }}
        BlockStorage: >-
          {{-
            {
              "ignore-volume-az": (
                "true"
                if capi_cluster_addons_openstack_block_storage_ignore_volume_az
                else "false"
              )
            } |
              combine(
                { "node-volume-attach-limit": capi_cluster_addons_openstack_block_storage_node_volume_attach_limit }
                if capi_cluster_addons_openstack_block_storage_node_volume_attach_limit
                else {}
              ) |
              combine(
                { "rescan-on-resize": "true" }
                if capi_cluster_addons_openstack_block_storage_rescan_on_resize
                else {}
              )
          }}
      csiCinder:
        storageClass: >-
          {{-
            { "availabilityZone": capi_cluster_addons_csi_cinder_availability_zone } |
              combine(
                { "volumeType": capi_cluster_addons_csi_cinder_volume_type }
                if capi_cluster_addons_csi_cinder_volume_type
                else {}
              )
          }}

capi_cluster_release_overrides: {}
capi_cluster_release_values: >-
  {{-
    { "clouds": { "openstack": capi_cluster_credentials.clouds[capi_cluster_cloud_name] } } |
      combine(
        { "clouds": { "openstack": { "auth": { "project_id": capi_cluster_openstack_project_id } } } },
        recursive = True
      ) |
      combine(
        { "cloudCACert": capi_cluster_openstack_ca_cert }
        if capi_cluster_openstack_ca_cert
        else { "clouds": { "openstack": { "verify": False } } },
        recursive = True
      ) |
      combine(capi_cluster_release_defaults, recursive = True) |
      combine(capi_cluster_release_overrides, recursive = True)
  }}

# The name of the file into which the kubeconfig of the cluster should be output
# If not given, the kubeconfig is not output
capi_cluster_kubeconfig_path:
